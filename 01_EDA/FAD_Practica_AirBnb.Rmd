---
title: "FAD_DataAnalysis_practica"
author: "Alvaro Simón Merino, Antonio Fernández Cáceres, Katsiaryna Zaitsava"
date: "13/11/2021"
output:
  html_document:
    theme: united
    code_folding: "hide"
    toc: yes
    toc_float: yes
  pdf_document: 
    theme: united
    code_folding: "hide"
    toc: yes
    toc_float: yes
---

---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 00 Descripción de la base de datos y librerias

Para la práctica hemos seleccionado el dataset *listings.csv* (Airbnb Madrid, 2021-09-10), una base de datos obtenida de insideairbnb.com con los alquileres de AirBnb de Madrid. Esta base de datos es de dominio público y consta de 22 variables con 18909 observaciones.

La base de datos puede descargarse en el siguiente enlace: http://insideairbnb.com/get-the-data.html


Las librerias usadas para esta práctica son las siguientes:

-caret
-dplyr
-ggplot2
-stringr
-readr
-batman
-knitr
-tidyr
-PASWR2
-scales
-nortest
-cowplot
-mice
-VIM
-corrplot
-psych
-ipred
-DMwR
-car

```{r include=FALSE, warning=FALSE}
library(caret)
library(dplyr)
library(ggplot2)
library(stringr)
library(readr)
library(batman)
library(knitr)
library(tidyr)
library(PASWR2)
library(scales)
library(nortest)
library(cowplot)
library(mice)
library(VIM)
library(corrplot)
library(psych)
library(ipred)
library(car)
library(geojsonio)
```
<br/>
<br/>

## 01 Introducción a la práctica

El turismo es una de las principales actividades economicas en España, antes del COVID-19 formaba una media de alrededor del 15,0% del PIB anual. Además, si tenemos en cuenta los tipos de actividades económicas adyacentes, la contribución del turismo será mucho mayor.

El turismo también es el generador de empleo más importante en España, con 2,83 millones de trabajadores turísticos registrados en 2019. De este modo, supera al sector salud con 2,71 millones de trabajadores, pero va por detrás del comercio con 3,19 millones. Sin embargo, el turismo ocupa el primer lugar en cuanto a empleo indirecto, con 1,87 millones de trabajadores, lo que representa el 66% del total de puestos de trabajo creados en el sector. Este indicador está impulsado por la gran cantidad de subsectores relacionados con el turismo y empresas auxiliares.

La actividad principal del turismo depende en gran medida de los servicios de alojamiento (hoteles, campings o casas) representados por los agregadores de reservas y alquileres más grandes, como Booking y Airbnb. En las condiciones actuales, muchas personas podrían quedarse sin trabajo, y una de las posibles opciones para ganar dinero en el contexto de la reducción de las restricciones en España es el alquiler de viviendas a turistas.

El autoempleo de la población en el ámbito del alojamiento turístico se manifiesta más claramente en el portal de Airbnb. Nuestro principal objetivo es predecir el precio del alquiler para futuros o actuales propietarios en Madrid, independientemente del factor estacional. Porque para los propietarios, el factor tiempo afecta relativamente de la misma manera, los días de alta demanda con oferta limitada aumentan los precios de alquiler (vacaciones, temporada turística, etc.). Con base en el precio previsto, el propietario podrá determinar el precio de alquiler de su propiedad, averiguar los factores que más afectan el precio de alquiler.
<br/>
<br/>

## 02 Definición de objetivos
Dado que la base de datos elegida está relacionada con el alquiler de viviendas, consideramos la variable "price", la cual representa el valor del precio del alquiler, como la variable objetivo de la práctica.
<br/>

### Objetivos generales
- Analizar las variables de la base de datos seleccionada para su comprensión y posterior estudio.
- Aplicar el módelo de regresión lineal múltiple para inferir la variable "price" seleccionada, que corresponde al precio de la vivienda.
<br/>

### Objetivos específicos : Pasos
1. Preparación de los datos.

2. Separar los datos en 2 grupos de datos: training + control y testing.
    - El grupo training + control contiene el 70% de los datos, con el cual entrenaremos el modelo. 
    - El grupo test contiene el 30% de los datos y se dejará como conjunto aislado hasta el final de la práctica como simulación de datos reales.

  Sobre el dataset de training:
     - transformar las variables, imputar datos (si procede);
     - proponer un modelo inicial (e.g. regresión lineal);
     - evaluar inicialmente el modelo mediante los resultados básicos ofrecidos por summary(model).
   
3. Realizar un análisis exploratorio inicial de cada una de las variables del grupo de training.
    - Se llevará a cabo separando las variables categóricas de las cualitativas para su posterior estudio.
    
4. Imputar las variables faltantes de la base de datos previo estudio
5. Aplicar las transformaciones necesarias a cada una de las variables.
6. Entrenar el modelo matemático de regresión lineal múltiple con las variables seleccionadas para la predicción de la variable 'precio'.
7. Usar el modelo propuesto para la predicción de la variable 'precio' con las variables del grupo testing.
    - Transformación de variables, imputación datos (si procede), siguiendo las mismas operaciones que para el caso de training.
    - Comparar con los datos de la columna real price en los datos de testing, para comprobar el porcentaje de aciertos/fallos.
    - Ajustar el modelo de regresión lineal siguiendo criterios contrastados (con la teoría vista hasta el momento), para decidir las variables         que incluímos en el modelo predictivo.
<br/>
<br/>

## 03 Ingesta,limpieza y separación de datos

Según el diccionario de datos proporcionado con los mismos, se adjunta el significado de cada variable de interés a extraer:

- $id$: identificador único de cada espacio alquilable.
- $host\_id$: identificador único de cada arrendador.
- $host\_since$: fecha en que el arrendador se dio de alta en la plataforma.
- $host\_is\_superhost$: indicador lógico de si el arrendador tiene excelentes puntuaciones.
- $neighbourhood\_group\_cleansed$: distrito en que se encuentra el espacio alquilable.
- $property\_type$: tipo de propiedad.
- $room\_type$: tipo de habitación.
- $accommodates$: capacidad máxima del espacio.
- $bedrooms$: número de cuartos de baño.
- $beds$: número de camas de la habitación.
- $price$: precio por noche en moneda local.
- $minimum\_nights$: mínimo de noches por estancia.
- $minimum\_nights\_avg\_ntm$: promedio de mínimo de noches durante los próximos 365 días.
- $maximum\_nights\_avg\_ntm$ promedio de máximo de noches durante los próximos 365 días.
- $availability\_365$: disponibilidad del espacio durante los próximos 365 días.
- $reviews\_per\_month$: media de número de reviews por airbnb durante un mes.

Las siguientes variables no aparecen en el diccionario, por lo que entramos a valorarlas: (TODO: revisar esto en alguna otra parte)

- $review\_scores\_rating$
- $review\_scores\_accuracy$
- $review\_scores\_cleanliness$
- $review\_scores\_checkin$
- $review\_scores\_communication$
- $review\_scores\_location$
- $review\_scores\_value$
<br/>

### Preparacion de los datos

#### Conjunto de datos

Trabajaremos con el conjunto de datos **RawData**, que contiene informacion sobre listados de Airbnb en Madrid (España) (2021-09-10).
```{r, echo=FALSE, warning=FALSE}
RawData <- read.csv("../00_DatosOriginales/listings.csv")
```
Este dataset esta formado por un total de `r nrow(RawData)` datos y `r ncol(RawData)` variables. 
<br/>

Basandonos en estudios previos similares ya realizados y un conocimiento preliminar de los datos, seleccionaremos las variables de interés del conjunto de datos, para su limpieza y estudio:

   - id 
   - host_id
   - host_since
   - host_is_superhost
   - description
   - neighbourhood_group_cleansed
   - latitude
   - longitude
   - property_type 
   - room_type 
   - accommodates
   - bedrooms 
   - beds
   - price
   - minimum_nights
   - minimun_nights_avg_ntm
   - maximum_nights_avg_ntm
   - availability_365
   - last_review
   - review_scores_rating
   - review_scores_accuracy
   - review_scores_cleanliness
   - review_scores_checkin 
   - review_scores_communication
   - review_scores_location
   - review_scores_value
   - reviews_per_month
   
Empezaremos con estas variables, aunque se intuye antes de comenzar que hay variables que no van a aportar mucho, o son similares a otras/combinaciones de varias. La variable 'beds', algunas de las variables de '_nights' y varias de las variables 'review_scores_', son potencialmente excluibles, pero haremos un análisis previo para justificarlo.

Guardamos las variables seleccionadas en un nuevo conjunto de datos *data*.
```{r datos, echo=FALSE, warning=FALSE}
data <- RawData %>%
   select(id, host_id, host_since, host_is_superhost,
          description, neighbourhood_group_cleansed, 
         latitude, longitude, property_type, room_type, 
         accommodates, bedrooms, beds, price, minimum_nights, minimum_nights_avg_ntm, maximum_nights_avg_ntm,
         availability_365, last_review, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, reviews_per_month)
```
<br/>

#### Limpieza de datos

Usamos la función str, para analizar la estructura de los datos en función a su contenido.

```{r str, echo=FALSE, warning=FALSE}
str(data)
```
Vemos que los tipos de datos de variables, como *host_since*, *last_review*, *host_is_superhost*, *price*, no tienen el formato adecuado para el tipo de variable. También encontramos valores faltantes en las variables (*host_since*, *host_is_superhost*, *description*, *last_review*), que denotamos como NA.
<br/>

##### Transformamos estos datos a sus formatos correctos.

   - formato *Date* para *host_since*, *last_review*, los valores faltantes se denotan como NA
```{r date, warning=FALSE}
data$host_since <- as.Date(data$host_since)
data$last_review <- as.Date(data$last_review)
```
<br/>

   - formato *logical* para *host_is_superhost*, los valores faltantes se denotan como NA
```{r host super, warning=FALSE}
data$host_is_superhost <- as.character(data$host_is_superhost)
data$host_is_superhost[which(data$host_is_superhost == "")] <- NA
data$host_is_superhost[which(data$host_is_superhost == "t")] <- "true"
data$host_is_superhost[which(data$host_is_superhost == "f")] <- "false"
data$host_is_superhost <- to_logical(data$host_is_superhost)
```
<br/>

   - formato *number* para *price*
```{r price, warning=FALSE}
data$price <- as.character(data$price)
data$price<-parse_number(data$price)
```
<br/>

   - formato *character* para *description*, los valores faltantes se denotan como NA 
```{r transform NA, warning=FALSE}
data$description <- as.character(data$description)
data$description[which(data$description == "")] <- NA
```   
<br/>

##### Comprobaremos el resultado obtenido.

```{r str 1, echo=FALSE, warning=FALSE}
str(data)
```
<br/>

Vamos a realizar algunas transformaciones más, que tienen sentido lógico previo al análisis exploratorio:

##### Eliminamos los valores de la variable 'price' que estén por debajo de 0.
```{r subset, warning=FALSE}
data <- subset(data, price > 0)
``` 
Como resultado, el conjunto de datos ha disminuido en 8 observaciones.
<br/>

##### Veamos el número total de valores perdidos para las variables.
```{r datos faltantes total, echo=FALSE, warning=FALSE}
colSums(is.na(data))
aggr(data, numbers=TRUE, sortVars=TRUE)
``` 
<br/>

```{r matrixplot, echo=FALSE, warning=FALSE}
matrixplot(data)
``` 
<br/>

<span style="color:red">(Revisar este apartado, no lo entiendo bien - Alvaro)</span>
En nuestro caso, no solo nos interesa la fecha de registro del propietario de la propiedad inmobiliaria en airbnb y la fecha de la última revisión, sino que nos interesa directamente la experiencia del propietario sobre el recurso y cuánto tiempo ha pasado desde la ultima revision de la propiedad.

Cuanta más experiencia tiene un vendedor, más confianza tienen los consumidores en él y, en consecuencia, más demanda, lo que tiene un efecto positivo en el precio. Las reseñas antiguas sobre el alojamiento llevan poca información para los consumidores, aumentan sus riesgos y, en consecuencia, la demanda cae, lo que afecta negativamente al precio.

Por lo tanto, en lugar de una variable, calcularemos la variable de la experiencia del propietario en el recurso *host_exp_days* (el número de días) y reemplazaremos la variable de la fecha de la última revocación por la variable del número de días desde la última revocación *last_review_days*.

```{r transform, warning=FALSE}
data$host_exp_days <- as.integer(max(data$host_since, na.rm = TRUE)-data$host_since)
data$last_review_days <- as.integer(max(data$last_review, na.rm = TRUE)-data$last_review)

data$host_since <- NULL
data$last_review <- NULL
```
<br/>

También nos interesa el número de alojamientos que tiene cada propietario.
<span style="color:red">Calcularemos (que quieres decir con esto Katia?)</span> y añadimos la variable *host_listings_count*.

```{r transform listings count, warning=FALSE}
data <- data %>%
  add_count(host_id)
colnames(data)[colnames(data) == 'n'] <- 'host_listings_count'
```
<br/>

Además del precio total del alquiler del alojamiento, nos interesa calcular el precio del alquiler por persona *price_per_person*.

```{r transform price/person, warning=FALSE}
data$price_per_person <- data$price/data$accommodates
```
<br/>

El número de ID únicos de los objetos de ubicación es igual al número de observaciones, por lo que no tiene sentido seguir utilizando esta variable para el análisis. Pero esta variable sirve para obtener el número de listing que tiene un host. 
```{r id null, warning=FALSE}
data$id <- NULL
```
<br/>

### Separación Train-Test

Ahora podemos dividir nuestros datos en 70% para grupo de training y 30% para grupo de testing. Separamos los datos por distritos, para un reparto más homogéneo en ambos grupos (*neighbourhood_group_cleansed*).

```{r slice, warning=FALSE}
set.seed(12345)
inTraining <- createDataPartition(pull(RawData, neighbourhood_group_cleansed),
                                  p = .7, list = FALSE, times = 1)
data_train <- slice(data, inTraining) 
data_test <- slice(data, -inTraining)
```
Obtuvimos  `r nrow(data_train)` observaciones en el conjunto de datos *data_train* y  `r nrow(data_test)` en el conjunto de datos *data_test*.
<br/>
<br/>

## 04 Análisis exploratorio inicial : EDA

### 04.01 Análisis Univariante

#### Estudio de la variable price

```{r precios, warning=FALSE}
price <- ggplot(data_train, aes(x=price, y=..density..)) + geom_histogram(binwidth = 10, fill='cadetblue4') + geom_density(alpha = .1, fill="white")

log_price <- ggplot(data_train, aes(x=price, y=..density..)) + geom_histogram(binwidth = 10, color='white', fill='cadetblue4') + geom_density(alpha = .1, fill="white") + xlim(c(0,500)) + ggtitle('Transformación logarítmica')

boxplot_price <- ggplot(data_train, aes(y=price)) + geom_boxplot(fill='cadetblue4') + scale_y_continuous(trans='log10')

quantile_price <- data.frame(quantile(data_train$price))

tbl <- tableGrob(quantile_price)

grid.arrange(price, log_price,boxplot_price,tbl, ncol=2, nrow =2, as.table=TRUE)
```
La variable $price$, la cual queremos predecir, en general se concentra entre los 37 y los 105€, y en general el número de Airbnbs decrece con el precio.
<br/>

#### Variable: neighbourhood_group_cleansed

```{r distritos, warning=FALSE}
cuentaDistritos <- data_train %>%
  group_by(neighbourhood_group_cleansed) %>%
  summarise(count = n()) %>%
  arrange(-count)

ggplot(data_train, aes(x=neighbourhood_group_cleansed, fill = neighbourhood_group_cleansed)) + geom_histogram(stat='count', color = '#262626') + coord_flip() + theme(legend.position = 'none') + ggtitle('Cantidad de Airbnbs por distrito') + ylab('Nº de Airbnbs') + xlab('Distritos')

#other_districts <- cuentaDistritos %>% slice(-c(1))
#centro_district <- cuentaDistritos %>% slice(c(1))
```
El estudio de esta variable es clave para entender la densidad de airbnbs por distrito. Aquí vemos claramente que el reparto de airbnbs por Madrid está en general homogeneizado en todos los distritos, excepto en el centro, dónde tiene una cantidad sumamente desproporcionada.
A continuación, imprimimos cada airbnb como un punto sobre un plano básico de distritos de madrid, usando un rango de color para la variable precio, para entender a nivel visual esta concentración, y ver si la localización afecta de algún modo a la variable objetivo. Aunque esto pertenece realmente al apartado de Análisis Multivariante, lo incluímos aquí por conveniencia y por una mejor relación visual.
<br/>

```{r mapa, fig.height=7, fig.width=6.5, warning=FALSE}
spdf <- geojson_read("../02_Resources/madrid-districts.geojson",  what = "sp")
spdf_fortified <- tidy(spdf)
spdf_df <- as.data.frame(spdf)
sorted_spdf_df <- spdf_df %>% arrange(name)

#Añadimos datos de población al geojson file
sorted_spdf_df$Poblacion_2017 = c(155660, 50010, 260196, 140473, 147551, 140866, 219867, 249973, 193264, 242139, 121683, 95614, 240867, 120406, 147854, 161222, 161313, 142894, 74048, 114512, 154318)

# Gráfico de airbnbs localizadas por latitud y longitud
adjusted_price <- subset(data_train, price >0 & price < 150)
price_map <- ggplot(adjusted_price, aes(x=longitude, y=latitude, color=price, alpha = 0.2)) + geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group), fill="grey", color="white", alpha = 0.4) + theme_void() + coord_map() + geom_point() + ggtitle('Airbnbs Madrid') + geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group), fill= NA, color="white", alpha = 0.1)
price_map
```
En este gráfico vemos una clara concentración de puntos en los distritos del centro de Madrid. También se puede apreciar que puede haber cierta relación entre la localización y el precio, ya que aunque hay fluctuación de intensidad de color generalizada, parece haber una ligera concentración de puntos claros más elevada en los distritos de la zona central. Trataremos de analizar con profundidad esta relación en el apartado de Análisis Multivariante.
<br/>

#### Variables : room type, accomodates, bedrooms y beds

```{r rooms & beds, warning=FALSE}
# Creamos una función para el GGPLOT
#ggplot_hist <- function(d, x){
#  ggplot(d, aes(x)) + geom_histogram(stat='count')
#}

# Tipos de rooms
room_type <- ggplot(data_train, aes(x=room_type, fill =room_type, alpha = room_type)) + geom_histogram(stat='count', col= 'black', fill='#00868B') + 
  theme(axis.text.x = element_text(size=8)) + theme(legend.position = "none")

cuentaTipos <- data_train %>%
  group_by(room_type) %>%
  summarise(count = n()) %>%
  arrange(-count)

# Tamaño de tablas para el grid
mytheme <- gridExtra::ttheme_default(
    core = list(fg_params=list(cex = 0.5)),
    colhead = list(fg_params=list(cex = 0.5)),
    rowhead = list(fg_params=list(cex = 0.5)))

# Tabla de room types
tbl_types <- gridExtra::tableGrob(cuentaTipos, theme = mytheme)

# Accomodates
accomodates <- ggplot(data_train, aes(x=accommodates)) + geom_histogram(stat='count', col= 'black', fill="palegreen4") + 
  theme(axis.text.x = element_text(size=8)) + theme(legend.position = "none")

cuentaAccommodates <- data_train %>%
  group_by(accommodates) %>%
  summarise(count = n()) %>%
  arrange(-count)

tbl_accom <- gridExtra::tableGrob(cuentaAccommodates, theme = mytheme)

# Bedrooms
bedrooms <- ggplot(data_train, aes(x=bedrooms)) + geom_histogram(stat='count', col= 'black', fill="orange3") + 
  theme(axis.text.x = element_text(size=8)) + theme(legend.position = "none")

cuentaBedrooms <- data_train %>%
  group_by(bedrooms) %>%
  summarise(count = n()) %>%
  arrange(-count)

tbl_bedroom <- gridExtra::tableGrob(cuentaBedrooms, theme = mytheme)

# Beds
beds <- ggplot(data_train, aes(x=beds, fill =beds, alpha = beds)) + geom_histogram(stat='count', col= 'black', fill ='#8B0000') + 
  theme(axis.text.x = element_text(size=8)) + theme(legend.position = "none")

cuentaBeds <- data_train %>%
  group_by(beds) %>%
  summarise(count = n()) %>%
  arrange(-count)

tbl_bed <- gridExtra::tableGrob(cuentaBeds, theme = mytheme)

# Agrupación de tablas
grid.arrange(beds, accomodates, bedrooms, room_type, ncol=2, nrow =2)
grid.arrange(tbl_bed, tbl_accom, tbl_bedroom, tbl_types, ncol=4, nrow =1, as.table=TRUE)
```
Tras el análisis de las variables, agrupadas por similitud, concluímos que:

  - Aproximadamente un tercio de las propiedades son para 2 personas, y la gran mayoría son para 6 o menos.
  - Dos tercios de las propiedades tienen 1 dormitorio, y el resto menos. Hay 1434 datos faltantes.
  - La mayoría de las propiedades tienen entre 1 y 4 camas.

A priori, se aprecia cierta relación entre algunos de los gráficos. Trataremos de profundizar en ello en el Análisis Multivariante.
<br/>

#### Variables min, máx nights, availability 360

```{r Nights, warning=FALSE}
# Min nights
min_nights <- ggplot(data_train, aes(x=minimum_nights)) + geom_histogram(bindwidth = 5, fill="violetred3", col='white')  + scale_y_continuous(trans='log10') + scale_x_continuous(limits = c(0, 400)) + theme(legend.position = "none")

cuentaMinNights <- data_train %>%
  group_by(minimum_nights) %>%
  summarise(count = n()) %>%
  arrange(-count)

tbl_min <- tableGrob(head(cuentaMinNights,10), theme = mytheme)

# Min nights average 360 days
min_night_avg <- ggplot(data_train, aes(x=minimum_nights_avg_ntm)) + geom_histogram(bindwidth = 5, fill="#CD853F", col='white')  + scale_y_continuous(trans='log10') + scale_x_continuous(limits = c(0, 400)) + theme(legend.position = "none")

cuentaMinNightsAvg <- data_train %>%
  group_by(minimum_nights_avg_ntm) %>%
  summarise(count = n()) %>%
  arrange(-count)

tbl_min_avg <- gridExtra::tableGrob(head(cuentaMinNightsAvg,10), theme = mytheme)

# Max nights average 360 days
max_night_avg <- ggplot(data_train, aes(x=maximum_nights_avg_ntm)) + geom_histogram(bindwidth = 5, fill="#40E0D0", col='white')  + scale_y_continuous(trans='log10') + xlim(c(0,2000))  + scale_x_continuous(limits = c(0, 400)) + theme(legend.position = "none")

cuentaMaxNightsAvg <- data_train %>%
  group_by(maximum_nights_avg_ntm) %>%
  summarise(count = n()) %>%
  arrange(-count)

tbl_max_avg <- gridExtra::tableGrob(head(cuentaMaxNightsAvg,10), theme = mytheme)

# availability_365
avail_360 <- ggplot(data_train, aes(x=availability_365)) + geom_histogram(bindwidth = 5, fill = 'orangered3', col='white')
sum(data_train$availability_365==0)

# Agrupación de tablas
grid.arrange(min_nights, min_night_avg, max_night_avg, avail_360, ncol=2, nrow =2)
grid.arrange(tbl_min, tbl_min_avg, tbl_max_avg, ncol=3, nrow =1, as.table=TRUE)
```
Se aprecia un relación clara entre las variables 'minimum_nights' y 'minimum_nights_avg_ntm', por tanto concluímos que es básicamente la misma variable. Nos quedaremos con la segunda por tratarse de la media anual, según la definición del diccionario de la base de datos.
<br/>

#### Variables review_scores

Observamos a priori, que se podría hacer una combinación de todas las variables distintas para review/scores haciendo una media, en una sola variable, y después estudiar la relación de esa variable con precio. Sería interesante hacer un análisis multivariante a tres, con las variables price, number_of_reviews y *final_scores (posible variable combinación de todas las otras)

Sería importante determinar también, si por el ejemplo la variable $review_scores_rating$ o la variable $review_scores_value$, son de hecho una combinación de las demás. Si podemos demostrar que una de estas variables es la media de todas las demás, podriamos simplemente quedarnos con una de estas y descartar el resto.
<br/>

##### Primero analizaremos las condiciones generales de las variables

```{r data, warning=FALSE}
scores <- data_train %>%
  select(review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, reviews_per_month)

head(scores)
summary(scores)

```

Se puede apreciar que todas tienen unas condiciones similares, con una media similar y con un sistema de puntuación númerica similar, excepto en un par de casos. Observamos además que todas tiene alrededor de 3600 NA más o menos. El primer paso sería comprobar si esos NAs coinciden en todas las variables, con respecto al ID, y más adelante determinar si es necesario imputarlos. A continuación, pasamos a analizar cada variable dentro de un conjunto de gráficas agrupadas para facilitar la comparación.

<br/>


#### Conjunto de Histogramas de todas las variables

```{r ratings, warning=FALSE}
rs_rating <- ggplot(scores, aes(x = review_scores_rating, y=..count..)) + 
  geom_histogram(binwidth = 0.5, color='black', fill = '#458B74') + xlab("Rating")+ ylab("count")
rs_accuracy <- ggplot(scores, aes(x = review_scores_accuracy, y=..count..)) + 
  geom_histogram(binwidth = 0.5, color='black', fill = '#8B2323') + xlab("Accuracy")+ ylab("count")
rs_cleanliness <- ggplot(scores, aes(x = review_scores_cleanliness, y=..count..)) + 
  geom_histogram(binwidth = 0.5, color='black', fill = 'dodgerblue3') + xlab("Cleanliness")+ ylab("count")
rs_checkin <- ggplot(scores, aes(x = review_scores_checkin, y=..count..)) + 
  geom_histogram(binwidth = 0.5, color='black', fill = 'darkgoldenrod2') + xlab("Check in")+ ylab("count")
rs_communication <- ggplot(scores, aes(x = review_scores_communication, y=..count..)) + 
  geom_histogram(binwidth = 0.5, color='black', fill = 'darkolivegreen3') + xlab("Communication")+ ylab("count")
rs_location <- ggplot(scores, aes(x = review_scores_location, y=..count..)) + 
  geom_histogram(binwidth = 0.5, color='black', fill = '#CD5B45')+ xlab("Location")+ ylab("count")
rs_value <- ggplot(scores, aes(x = review_scores_value, y=..count..)) + 
  geom_histogram(binwidth = 0.5, color='black', fill = '#008B8B')+ xlab("Value")+ ylab("count")
rp_month <- ggplot(scores, aes(x = reviews_per_month, y=..count..)) + 
  geom_histogram(binwidth = 0.7, fill = '#CD5555') + xlab("Per month")+ ylab("count")

grid.arrange(rs_rating, rs_accuracy, rs_cleanliness, rs_checkin, rs_communication, rs_location, rs_value, rp_month, ncol=4, nrow =2)
```
<br/>

Podemos observar que la mayoría de las reviews son positivas, con la mayor concentración de casos entre el 4 y el 5 generalmente.
Reviews per month tiene un formato poco legible en el eje de las x, vamos a analizarla por separado para entender los datos un poco mejor.

```{r per month, warning=FALSE}
str(scores$reviews_per_month)
summary(scores$reviews_per_month)
rpmonth <- na.omit(scores$reviews_per_month)
summary(rpmonth)

# Creación del layout para diagramas
layout(matrix(c(1,2),2,1, byrow=TRUE), height = c(1,8))
 
# Boxplot e histograma combinados
par(mar=c(0, 5.1, 1.1, 2.1))
boxplot(rpmonth , horizontal=TRUE , ylim=c(0,20), xaxt="n" , col=rgb(0.2,0.8,0.5,0.5) , frame=F)
par(mar=c(4.5, 5.1, 1.1, 2.1))
hist(rpmonth , breaks=40 , col='#CD5555' , border=F , main="", ylab="nº reviews", xlab="Media de reviews en 30", xlim=c(0,8))

```
<br/>

Como podemos apreciar en este gráfico, la mayoria de los airbnb en la base de datos, obtienen entre 0 y 2 reviews por mes de media, con más de 4000 personas con una media de 0.25 reviews por mes. Este resultado tiene sentido, ya que en general las personas suelen estar un par de semanas de vacaciones, y suele haber mayor concetración de turistas en ciertos meses del año. 

#### host_since

```{r host_since, warning=FALSE}
ggplot(data_train, aes(x=host_since)) + geom_histogram(binwidth = 30)

```


#### host_is_superhost

```{r host_is_superhost, warning=FALSE}
ggplot(data_train, aes(x=host_is_superhost)) + geom_histogram(stat="count")
```

### 4. Análisis exploratorio multivariante del precio

#### price vs room_type

```{r priceVSroomtype}
ggplot(data, aes(x=room_type, y=price)) + geom_boxplot() + scale_y_continuous(trans='log10')
```

#### price vs neighbourhood_group_cleansed

```{r priceVSneigh}
ggplot(data, aes(x=neighbourhood_group_cleansed, y=price)) + geom_boxplot() + scale_y_continuous(trans='log10') + coord_flip()# CHECK: relevant
```

#### price vs host_since
```{r priceVShost_since}
ggplot(data, aes(x=host_since, y=price)) + geom_col() + scale_y_continuous(trans='log10') # CHECK: Irrelevant TODO: agregar por promedio
```


#### price vs host_is_superhost
```{r priceVSsuperhost}
ggplot(data, aes(x=host_is_superhost, y=price)) + geom_boxplot() + scale_y_continuous(trans='log10') #CHECK: bit of an edge
```

#### price vs accommodates
```{r priceVSaccommodates}
pricevsAcco <- data %>%
  group_by(accommodates) %>%
  summarise(precio = mean(price))

ggplot(pricevsAcco, aes(x=accommodates, y=precio)) + geom_col() # CHECK: Fairly obvious
```

#### price vs bedrooms

```{r priceVSbedrooms}
pricevsBR <- data %>%
  group_by(bedrooms) %>%
  summarise(precio = mean(price))

ggplot(pricevsBR, aes(x=bedrooms, y=precio)) + geom_col() # CHECK: accommodates are better
```


#### price vs beds

```{r priceVSbeds}
pricevsBeds <- data %>%
  group_by(beds) %>%
  summarise(precio = mean(price))

ggplot(pricevsBeds, aes(x=beds, y=precio)) + geom_col() # CHECK: Fairly obvious. Accommodates can be better.
```

#### price vs minimum_nights

```{r priceVSminimum_nights}
pricevsminimum_nights <- data %>%
  group_by(minimum_nights) %>%
  summarise(precio = mean(price))

ggplot(pricevsminimum_nights, aes(x=minimum_nights, y=precio)) + geom_col() # No value
```

#### price vs minimum_nights_avg_ntm

```{r priceVSminimum_nights_avg_ntm}
pricevsminimum_nights_avg_ntm <- data %>%
  group_by(minimum_nights_avg_ntm) %>%
  summarise(precio = mean(price))

ggplot(pricevsminimum_nights_avg_ntm, aes(x=minimum_nights_avg_ntm, y=precio)) + geom_col() + scale_y_continuous(trans='log10') #¿?
```

#### price vs maximum_nights_avg_ntm

```{r priceVSmaximum_nights_avg_ntm}
pricevsmaximum_nights_avg_ntm <- data %>%
  group_by(maximum_nights_avg_ntm) %>%
  summarise(precio = mean(price))

ggplot(pricevsmaximum_nights_avg_ntm, aes(x=maximum_nights_avg_ntm, y=precio)) + geom_col() # No value
```

#### price vs availability_365

```{r priceVSavailability_365}
pricevsavailability_365 <- data %>%
  group_by(availability_365) %>%
  summarise(precio = mean(price))

ggplot(pricevsavailability_365, aes(x=availability_365, y=precio)) + geom_col() # CHECK: can seasonality be borrowed from here and scraping date?
```


#### reviews_per_month vs price

```{r priceVSreviews_per_month}
ggplot(data, aes(x=reviews_per_month, y=price)) + geom_point()
```

#### review_scores_rating vs price

```{r priceVSreview_scores_rating}
ggplot(data, aes(x=review_scores_rating, y=price)) + geom_point()
```

### 5. Análisis detallado multivariante del precio


#### 5.1 Subdivisión en categorías

##### 5.1.1 Ajustar al número de camas:

```{r priceperperson}
data$price_per_person = data$price/data$accommodates
```

```{r propertyCostPerPerson}
ggplot(data, aes(x=room_type, y=price_per_person)) + geom_boxplot() + scale_y_continuous(trans='log10')
```

#### neighbourhood_group_cleansed

```{r priceperbedVSneigh}
ggplot(data, aes(x=neighbourhood_group_cleansed, y=price_per_person)) + geom_boxplot() + scale_y_continuous(trans='log10')
```

##### Canillejas case

```{r canillejas}

dataCan <- data[data$neighbourhood_group_cleansed=="San Blas - Canillejas",]
count(dataCan)

ggplot(dataCan, aes(x=room_type, y=price_per_person)) + geom_boxplot() + scale_y_continuous(trans='log10')

count(dataCan %>% group_by(room_type))

dataCan[dataCan$room_type=="Shared room","description"] # Check: Resuelto el misterio de los pisos caros. Están cerca del Wanda. Contémoslos:

cercaWanda <- dataCan[grep("wanda|estadio", tolower(dataCan$description)),]
lejosWanda <- anti_join(dataCan, cercaWanda)


ggplot(cercaWanda, aes(x=room_type, y=price_per_person)) + geom_boxplot() + scale_y_continuous(trans='log10') # Resueltísimo: Habitaciones privadas y compartidas
ggplot(lejosWanda, aes(x=room_type, y=price_per_person)) + geom_boxplot() + scale_y_continuous(trans='log10') # Resueltísimo
```

##### neighbourhoods without Wanda
```{r neighNoWanda}

neighNoWanda <- anti_join(data, cercaWanda)

ggplot(neighNoWanda, aes(x=neighbourhood_group_cleansed, y=price_per_person)) + geom_boxplot() + scale_y_continuous(trans='log10')

```

### 06 Análisis de outliers


```{r outliers, warning=FALSE}

outliers <- data_train[data$price > quantile(data_train$price)[4],]

count(outliers)

ggplot(outliers, aes(x=price)) + geom_histogram(binwidth = 10)

ggplot(outliers, aes(y=price)) + geom_boxplot() + scale_y_continuous(trans = 'log10')

outliers <- outliers %>% mutate(pricePP = price/accommodates)

quantile(outliers$pricePP)

outliersPerPerson <- outliers[(outliers$pricePP) > quantile(outliers$pricePP)[4],]

ggplot(outliersPerPerson, aes(y=pricePP)) + geom_boxplot() + scale_y_continuous(trans = 'log10')

count(outliersPerPerson[outliersPerPerson$pricePP > 1000, ])

head(outliersPerPerson[outliersPerPerson$pricePP > 1000, "description"])

insane <- outliersPerPerson[outliersPerPerson$pricePP > 1000,]

count(insane)

summary(insane)

ggplot(insane, aes(x=price)) + geom_histogram()

cuentaDistritosInsane <- insane %>%
  group_by(neighbourhood_group_cleansed) %>%
  summarise(count = n()) %>%
  arrange(-count)

ggplot(insane, aes(x=neighbourhood_group_cleansed)) + geom_histogram(stat='count')

ggplot(insane, aes(x=room_type, y=pricePP)) + geom_boxplot()

insane$accommodates

insane$pricePP

insane[insane$neighbourhood_group_cleansed=="Villaverde", c("description","price")]

insane$reviews_per_month

# TODO Yo todo lo que supere los 105-150€/persona lo quitaba

```


## 06.01 Estudio de valores faltantes

```{r summary, warning=FALSE}
summary(data)
```


### Viendo el summary se puede comprobar que:

* $host\_since$ tiene 16 NAs.

* $bedrooms$ tiene 1022 NAs.

* $price$ no tiene NAs, pero el máximo es $9999.0, lo cual no parece verosímil.

* $minimum\_nights\_avg\_ntm$ y $maximum\_nights\_avg\_ntm$ tienen 1 NA. Deberíamos comprobar si pertenecen al mismo id.

* Es factible que $availability\_365$ tenga valores a 0, pero altamente improbable. Debemos estudiarlo.

* Hay más de 3000 NA en todas las variables de Review.


### Mostramos el gráfico de la distribución del número de valores perdidos.

```{r grafico, echo=FALSE, fig.height=5, fig.width=7.5, warning=FALSE}
na_vis <- data.frame(t(colSums(is.na(data_train))))
na_bar <- data.frame(Features = names(na_vis),totals=colSums(na_vis))

na_bar %>% ggplot(aes(x = reorder(Features, totals), y = totals, fill = Features, label = totals))+
  geom_bar(stat = "identity")+
  ggtitle("NA Distribution")+
  xlab("Variables")+
  ylab("Total NAs")+
  coord_flip()+
  geom_text(size = 2, position = position_stack(vjust = 0.5))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5)) + theme(legend.text = element_text(colour="black", size = 8))
```

```{r fig.height=7, fig.width=8, warning=FALSE}
md.pattern(data_train, rotate.names=TRUE)
``` 


Tenemos una pequeña cantidad de valores faltantes en *host_is_superhost* y *host_exp_days*, solo 19 observaciones. En este caso, los valores faltantes se pueden reemplazar directamente:
   - NA = false para *host_is_superhost*;
   - NA = 0 para *host_exp_days*
 
```{r na min, warning=FALSE}
# en primero vamos a guardardatos modificados en nuevo dataset data_train_del_na para tener accesso de datos previos

data_train_del_na <- data_train
data_train_del_na$host_is_superhost[which(is.na(data_train_del_na$host_is_superhost))] <- FALSE
data_train_del_na$host_exp_days[which(is.na(data_train_del_na$host_exp_days))] <- 0
```  

Construyamos una matriz de correlación de valores NA para otros variables (*neighbourhood*, *bedrooms*, *review_scores_rating*,  *reviews_per_month*, *last_review_days*).

```{r cor na, warning=FALSE}
x <- as.data.frame(abs(is.na(data_train_del_na)))
y <- x[, which(colSums(x) > 0)]

print(cor(y))
```  

```{r datos faltantes train, echo=FALSE, warning=FALSE}

colSums(is.na(data_train_del_na))
aggr(data_train_del_na, numbers=TRUE, sortVars=TRUE)
``` 

Vemos que para las mismas observaciones existen valores para las variables *review_scores_rating*,  *reviews_per_month*, *last_review_days*. Para estas variables faltan 26,6% de observaciones y para *bedrooms* - 7,5%.

Para seleccionar un método para completar los valores faltantes, primero definimos variables altamente correlacionadas que pueden conducir a una multicolinealidad y, en consecuencia, la imposibilidad de utilizar unos métodos de cálculo.

```{r datos high corr,  echo=FALSE, warning=FALSE}
high.corr<-function(x){
  df<-x[sapply(x,is.numeric)]
  fit<-corr.test(df)
  diag(fit$r)<-0
  inds <- which(abs(fit$r) > 0.5, arr.ind=TRUE)
  return(rownames(inds))
}


high.corr(data_train_del_na)

``` 

Vemos que existe un nivel relativamente alto de correlación entre las variables *bedrooms* y *accommodates* (`r cor(data_train$bedrooms, data_train$accommodates, use="complete.obs")`).

#### Imputacion por regresion

Intentamos imputar datos faltantes de variable *bedrooms* usando regresion lineal, como sabemos que hay correlacion alta entre esta variable y variable *accommodates*.

```{r datos na line,  echo=FALSE, warning=FALSE}
fit <- with(data_train_del_na, lm(bedrooms ~ accommodates))
summary(fit)
``` 

Vemos que los coeficientes de regresión lineal son significativos, sin embargo, R es lo suficientemente pequeño y explica solo el 47,6% de variación.

Veamos en qué se diferencian los valores predichos de los originales. 

```{r datos na line result,  echo=FALSE, warning=FALSE}
actuals <- data_train_del_na$bedrooms[!is.na(data_train_del_na$bedrooms)]
pred_lm <- predict(lm( bedrooms ~ accommodates, data = data_train_del_na[!is.na(data_train_del_na$bedrooms), ]))
regr.eval(actuals, pred_lm)
``` 
El error porcentual absoluto medio (mape) fue 26,4%, que es un indicador insatisfactorio. Probamos otros methodos.

#### Imputacion con paquete mice

Como tenemos alta probabilidad de que una columna sea una combinación lineal de otra vamos usar methodos *rf* y *cart* de paquete *mice*. Los métodos de imputación predeterminados de  *mice*, que implican regresión lineal, en nuestro caso van dar como resultado una matriz X que no se puede invertir y dará como resultado su error.

Utilizando este paquete, podemos imputar datos faltantes para todas variables, quales tienen NA.

Resultatos para *random forest*.

```{r datos imp rf, echo=FALSE, warning=FALSE}

miceMod <- mice(data_train_del_na[, !names(data_train_del_na) %in% c("price", "price_per_person", "description")], method="rf", seed = 123)  
miceOutput <- complete(miceMod)
``` 

Comprobamos, si hay algunos NA en conjunto de datos.

```{r datos imp rf na, echo=FALSE, warning=FALSE}
anyNA(miceOutput) # False
``` 

Pues en output no tenemos datos faltantes.
Comparemos qué tan cercana es la distribución de los datos recibidos a los actuales. Mostramos el gráfico *densityplot*.

```{r datos imp rf graph, echo=FALSE, warning=FALSE}
densityplot(miceMod, xlim = c(2.5, 17.5), ylim = c(0, 0.4))
``` 

Resultatos para *cart* (classification and regression trees).

```{r datos imp cart, echo=FALSE, warning=FALSE}
miceMod_cart <- mice(data_train_del_na[, !names(data_train_del_na) %in% c("price", "price_per_person", "description")], method="cart", seed = 123)  
miceOutput_cart <- complete(miceMod_cart)
``` 

Comprobamos, si hay algunos NA en conjunto de datos.

```{r datos imp cart na, echo=FALSE, warning=FALSE}
anyNA(miceOutput_cart) # False
``` 

Pues en output no tenemos datos faltantes.
Comparemos qué tan cercana es la distribución de los datos recibidos a los actuales. Mostramos el gráfico *densityplot*.

```{r datos imp cart graph, echo=FALSE, warning=FALSE}
densityplot(miceMod_cart, xlim = c(2.5, 17.5), ylim = c(0, 0.4))
``` 

Nos vemos que datos imputados son muy cercanos de lo datos observados, pero mejor resultado para variables lo da el methodo *cart*. Usamos este methodo para nuestras variables con NA.

```{r datos imputacion, echo=FALSE, warning=FALSE}
data_train_del_na$bedrooms[which(is.na(data_train_del_na$bedrooms))] <- miceOutput_cart[is.na(data_train_del_na$bedrooms), "bedrooms"]

data_train_del_na$review_scores_rating[which(is.na(data_train_del_na$review_scores_rating))] <- miceOutput_cart[is.na(data_train_del_na$review_scores_rating), "review_scores_rating"]

data_train_del_na$reviews_per_month[which(is.na(data_train_del_na$reviews_per_month))] <- miceOutput_cart[is.na(data_train_del_na$reviews_per_month), "reviews_per_month"]

data_train_del_na$last_review_days[which(is.na(data_train_del_na$last_review_days))] <- miceOutput_cart[is.na(data_train_del_na$last_review_days), "last_review_days"]
``` 

Veamos, si hemos han imputado todos datos faltantes en nuestro conjunto de datos *data_train*.
```{r datos cart na, echo=FALSE, warning=FALSE}
colSums(is.na(data_train_del_na)) # False
``` 

En resultado ya tenemos *data_train* sin datos faltantes y podemos mas eficaz trabajar con el.

### Deteccion de valores atipicos

Comprobamos si hay algunos datos atipicos en nuestro conjunto de datos.

```{r datos sum, echo=FALSE, warning=FALSE}
summary(data_train_del_na)
``` 

Vemos, que valores atipicos pueden tener variables *accommodates*, *bedrooms*, *price*, *minimum_nights*, *reviews_per_month*, *last_review_days*, *host_listings_count*, *price_per_person*. Revisamos estas variables mas detallado.

#### Valores atipicos de variable accommodates

Construyamos gráficos.

```{r datos acc graph, echo=FALSE, warning=FALSE}

plot(data_train_del_na$accommodates)

ggplot(data = data_train_del_na) + 
   aes(x = accommodates) + 
   geom_boxplot(outlier.colour = "Red", fill = "orange") + 
   theme_bw()


ggplot(data = data_train_del_na) + 
   aes(x = accommodates) + 
   geom_dotplot(dotsize = 0.1,color = "green") +
   theme_minimal()
``` 


#### Valores atipicos de variable bedrooms

Construyamos gráficos.

```{r datos b graph, echo=FALSE, warning=FALSE}
plot(data_train_del_na$bedrooms)

ggplot(data = data_train_del_na) + 
   aes(x = bedrooms) + 
   geom_boxplot(outlier.colour = "Red", fill = "green") + 
   theme_bw()


ggplot(data = data_train_del_na) + 
   aes(x = bedrooms) + 
   geom_dotplot(dotsize = 0.1,color = "blue") +
   theme_minimal()
``` 


#### Valores atipicos de variable minimum_nights

Construyamos gráficos.

```{r datos m_n graph, echo=FALSE, warning=FALSE}
plot(data_train_del_na$minimum_nights)

ggplot(data = data_train_del_na) + 
   aes(x = minimum_nights) + 
   geom_boxplot(outlier.colour = "Red", fill = "yellow") + 
   theme_bw()

ggplot(data = data_train_del_na) + 
   aes(x = minimum_nights) + 
   geom_dotplot(dotsize = 0.1,color = "violet") +
   theme_minimal()
``` 

Variable de mínimos noches muestra la presencia de valores atípicos, por lo que requiere modificaciones. Como es inusual que las noches mínimas estén por encima de 100 en cualquier airbnb, es claramente un valor atípico y debe eliminarse de nuestros datos.


```{r outliers nights, echo=FALSE, warning=FALSE}
# en primero vamos a guardardatos modificados en nuevo dataset data_train_clean para tener accesso de datos previos

data_train_clean <- data_train_del_na

uc1 = quantile(data_train_clean$minimum_nights, probs = 0.95, na.rm = TRUE)
  lc1 = quantile(data_train_clean$minimum_nights, probs = 0.05, na.rm = TRUE)
  data_train <- subset(data_train_clean, minimum_nights >= lc1 & minimum_nights <= uc1)

summary(data_train_clean$minimum_nights)
```

```{r datos m_n graph outliers delete, echo=FALSE, warning=FALSE}
ggplot(data = data_train_clean) + 
   aes(x = minimum_nights) + 
   geom_boxplot(outlier.colour = "Red", fill = "yellow") + 
   theme_bw()
``` 

#### Valores atipicos de variable price y price_per_person

Construyamos gráficos.
```{r datos pr p graph, echo=FALSE, warning=FALSE}
plot(data_train_clean$price)

ggplot(data = data_train_clean) + 
   aes(x = price) + 
   geom_boxplot(outlier.colour = "Red", fill = "blue") + 
   theme_bw()


ggplot(data = data_train_clean) + 
   aes(x = price) + 
   geom_dotplot(dotsize = 0.1,color = "red") +
   theme_minimal()
``` 


```{r datos pr p graph, echo=FALSE, warning=FALSE}
plot(data_train_clean$price_per_person)

ggplot(data = data_train_clean) + 
   aes(x = price_per_person) + 
   geom_boxplot(outlier.colour = "Red", fill = "blue") + 
   theme_bw()

ggplot(data = data_train_clean) + 
   aes(x = price_per_person) + 
   geom_dotplot(dotsize = 0.1,color = "red") +
   theme_minimal()
``` 

Variable de precios por persona muestra la presencia de valores atípicos, por lo que requiere modificaciones. Como es inusual que la una noche para una persona vale 9000 euros.

```{r outliers price, echo=FALSE, warning=FALSE}

uc1 = quantile(data_train_clean$price_per_person, probs = 0.95, na.rm = TRUE)
  lc1 = quantile(data_train_clean$price_per_person, probs = 0.05, na.rm = TRUE)
  data_train <- subset(data_train_clean, price_per_person >= lc1 & price_per_person <= uc1)

summary(data_train_clean$price_per_person)
```

```{r outliers pr, echo=FALSE, warning=FALSE}
summary(data_train_clean$price)
```

```{r datos pr graph, echo=FALSE, warning=FALSE}

ggplot(data = data_train_clean) + 
   aes(x = price) + 
   geom_boxplot(outlier.colour = "Red", fill = "blue") + 
   theme_bw()

ggplot(data = data_train_clean) + 
   aes(x = price_per_person) + 
   geom_boxplot(outlier.colour = "Red", fill = "blue") + 
   theme_bw()
``` 

#### Valores atipicos de variable minimum_nights

Construyamos gráficos.

```{r datos m_n graph, echo=FALSE, warning=FALSE}
plot(data_train$minimum_nights)

ggplot(data = data_train) + 
   aes(x = minimum_nights) + 
   geom_boxplot(outlier.colour = "Red", fill = "yellow") + 
   theme_bw()

ggplot(data = data_train) + 
   aes(x = minimum_nights) + 
   geom_dotplot(dotsize = 0.1,color = "violet") +
   theme_minimal()
``` 


#### Valores atipicos de variable reviews_per_month

Construyamos gráficos.

```{r datos r_m gr, echo=FALSE, warning=FALSE}

plot(data_train_clean$reviews_per_month)
   aes(x = reviews_per_month) + 
   geom_boxplot(outlier.colour = "Red", fill = "violet") + 
   theme_bw()


ggplot(data = data_train_clean) + 
   aes(x = reviews_per_month) + 
   geom_dotplot(dotsize = 0.1,color = "orange") +
   theme_minimal()
``` 

#### Valores atipicos de variable last_review_days

Construyamos gráficos.

```{r datos l_r graph, echo=FALSE, warning=FALSE}

plot(data_train_clean$last_review_days)

ggplot(data = data_train_clean) + 
   aes(x = last_review_days) + 
   geom_boxplot(outlier.colour = "Red", fill = "orange") + 
   theme_bw()


ggplot(data = data_train_clean) + 
   aes(x = last_review_days) + 
   geom_dotplot(dotsize = 0.1,color = "navy") +
   theme_minimal()
``` 


#### Valores atipicos de variable host_listings_count

Construyamos gráficos.

```{r datos coun graph, echo=FALSE, warning=FALSE}
plot(data_train_clean$host_listings_count)

ggplot(data = data_train_clean) + 
   aes(x = host_listings_count) + 
   geom_boxplot(outlier.colour = "Red", fill = "orange") + 
   theme_bw()

ggplot(data = data_train_clean) + 
   aes(x = host_listings_count) + 
   geom_dotplot(dotsize = 0.1,color = "navy") +
   theme_minimal()
``` 

```{r outliers count, echo=FALSE, warning=FALSE}

uc1 = quantile(data_train_clean$host_listings_count, probs = 0.95, na.rm = TRUE)
  lc1 = quantile(data_train_clean$host_listings_count, probs = 0.05, na.rm = TRUE)
  data_train <- subset(data_train_clean, host_listings_count >= lc1 & host_listings_count <= uc1)

summary(data_train_clean$host_listings_count)
```

```{r datos c out graph, echo=FALSE, warning=FALSE}
ggplot(data = data_train_clean) + 
   aes(x = host_listings_count) + 
   geom_boxplot(outlier.colour = "Red", fill = "orange") + 
   theme_bw()
```  


```{r outliers sresult, echo=FALSE, warning=FALSE}
summary(data_train_clean)
```

En resumen eleminamos valores atipicos para variables *minimum_nights*, *price_per_person*, *host_listings_count*.
<br/>
<br/>
